\chapter{Preliminaries}
\label{chapter:preliminaries}

In this chapter we will introduce Robotour competition,
go through some basic techniques of image segmentation,
explain convolutional neural networks and its impact on image segmentation. We will
also mention quite new approach for faster learning called active learning.

\section{Robotour competition}
\label{sec:robotour}

Robotour is an annual competition for outdoor robots being held in different locations,
which are mostly parks.
The participants are challenged to build an autonomous robot which completes the task
without breaking rules. The robot starts at the position $A$
(also called the base, where it is possible to repair or calibrate the robot) and
is given GPS coordinates of position $B$. Then, the robot must navigate itself through
the park to the location $B$ where organizers of the competition load a five liter
barrel of beer onto it. The robot is once again given coordinates, but this time
of position $C$,
where it is supposed to deliver the barrel. After unloading, the final goal is to return
back to the base.

The robot is forbidden to neither leave the driveable path nor touch any obstacle during
the round. If such thing happens, the robot is immediately disqualified from the round.
Therefore, it is important for the robot to prevent breaking the rules. Avoiding
obstacles is done quite accurately using laser and ultrasonic sensors mounted on the
robot. We will focus on the problem of differentiating between two categories within
given image: driveable or non-driveable path using computer vision techniques.

\section{Image segmentation}
\label{sec:image_segmentation}

Extracting useful information from images is an inevitable step for image analysis.
Image segmentation is a computer vision task of automatic image analysis, which
is at the middle layer of image engineering. Image engineering consists out of 3 steps,
which are 1) image processing, 2) image analysis and 3) image understanding.
Its main task is to partition an image into multiple
classes and extracting objects or regions of interest from background.
Each pixel within this image is assigned a class or a category which
it belongs to. Pixels with the same label share certain characteristics.
\cite{zhang2009image}

The history of image segmentation can be traced back to 50 years ago.
Since then, many techniques have been developed and evaluated.
We are going to describe some of them.
One of ist them also machine learning technique called convolutional neural networks
(CNN), which we will describe in the section \ref{sec:cnn}.

\subsection{Region based segmentation}
\label{sec:image_segmentation:region_based}

\subsubsection{Threshold segmentation}
\label{sec:image_segmentation:region_based:threshold}

Threshold segmentation is one of the most commonly used and simplest techniques.
The input image is transformed into gray scale representation. There are available
global and local threshold methods to be used. The former uses just one global threshold
value and divides the image just into two regions - target and background. On the other
hand, local threshold method uses multiple threshold values to divide the image
into multiple target and background regions.

The simple calculations make this method very fast. If the contrast between
background and the target is high enough, the segmentation can be computed quite
accurately. The disadvantage of this method is that it is difficult to obtain
accurate results where there is no significant difference in gray scale image, since
it does not take the spatial information into account. \cite{yuheng2017image}

\subsubsection{Regional growth segmentation}
\label{sec:image_segmentation:region_based:reggrowth}

The basic idea of regional growth segmentation method is to merge neighboring
pixels (or regions) that share similar properties into one. The first step
is to select so called seed pixels. We then grow regions from them, merging pixels
if their absolute difference is less or equal to some threshold $T$.
Visiting pixels in input is done by breadth-first search.

The disadvantages of aforementioned method is that it is computationally expensive
and local method with no global view and it is quite sensitive to noise .

Below, there is an example of the algorithm on input (leftmost) matrix. The middle
matrix was computed using threshold $T=3$ and the second one using $T=6$. We can clearly
see that the choice of threshold value is very important step for this algorithm
to work properly. \cite{yuheng2017image}

$$\begin{bmatrix}
\textbf{1} & 0 & 4 & 7 & \textbf{5} \\
1 & 0 & 5 & 7 & 7 \\
0 & 1 & 5 & 5 & 5 \\
2 & 0 & 5 & 6 & 5 \\
2 & 2 & 5 & 6 & 4
\end{bmatrix}
\hspace{2cm}
\begin{bmatrix}
1 & 1 & 5 & 5 & 5 \\
1 & 1 & 5 & 5 & 5 \\
1 & 1 & 5 & 5 & 5 \\
1 & 1 & 5 & 5 & 5 \\
1 & 1 & 5 & 5 & 5
\end{bmatrix}
\hspace{2cm}
\begin{bmatrix}
1 & 1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 & 1
\end{bmatrix}
$$

\subsection{Edge detection segmentation}
\label{sec:image_segmentation:edge_based}

Edges represent the most significant changes in the image. That means changes in
brightness, colors, etc. 

\cite{yuheng2017image}

\subsection{Clustering based segmentation}
\label{sec:image_segmentation:cluster_based}

Clustering is widely known as a method of iterating over samples in a feature space
and computing the nearest cluster they belong to. After convergence of pixels,
we can map them back to the original image to get the segmentation results.

The most used clustering algorithm is K-means. It works in four steps:

\begin{enumerate}
	\item Initialize clusters - select random samples to be the centroids of the cluster
	\item Assign each sample to cluster - calculate the distance from each cluster and
	assign the sample to the nearest one
	\item Recompute the centroid of each cluster by taking the mean of its samples
	\item Repeat steps 2 and 3 until none of the samples changes the cluster
\end{enumerate}

The K-means algorithm is fast and easy to implement and scalable to large
data sets. Unfortunately, the parameter $K$ (the number of clusters)
is difficult to estimate and has to be chosen experimentally.
As they say in \cite{bib:yuheng2017image}, it is distance-based partitioning method and
therefore it is only applicable to convex data sets.

\section{Convolutional neural networks}
\label{sec:cnn}

Convolutional neural networks (CNN or ConvNet) are a class of deep neural networks.
They are quite similar to ordinary neural networks, because they are made up of
neurons that have learnable weights and biases.
Most of the time it
is applied to computer vision problems like image classification, instance segmentation,
semantic segmentation and so on.

Every ConvNet architecture consists of three basic layers:
\begin{itemize}
	\item Convolutional layer - computing the output of neurons, that are
	connected to local regions in the input. Each neuron computes the dot product
	between this small region and the neuron's weights.
	\item Pooling layer - downsamples the input along the spatial dimensions, so the
	width and height will be smaller
	\item Fully-connected layer - computes the class score 
\end{itemize}

The CNN is then a sequence of layers. It takes an image as an input and transforms
it layer by layer and outputs the final prediction. The CNN is given so called training
and validation data, which are used during the training process. Each sample image
is fed into CNN and the output is compared to the ground truth. The network's weights
are then updated using backpropagation.

We can clearly see from the results that ConvNets are so powerful that they have
overcome classic image segmentation techniques known before and are now
state-of-the-art. 

\section{Active learning}
\label{sec:active_learning}

TODO
